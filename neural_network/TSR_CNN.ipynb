{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1WtoaOHVrVh"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    "    MaxPooling2D,\n",
    ")\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PATH = \"C:\\\\ImageSets\\\\SmallSetAugmentedNormalized8x8Old\"\n",
    "PREPROCESSED_IMAGES_PATH = \"C:\\\\new_set_of_augmented_images\"\n",
    "BEFORE_AUGMENTATION_IMAGES_PATH = \"C:\\\\images\"\n",
    "AUGMENTED_IMAGES_PATH = \"C:\\\\ImageSets\\\\SmallSetAugmented\\\\test\\\\aug_other\"\n",
    "\n",
    "TEST_DIR = os.path.join(PATH, \"test\")\n",
    "TRAIN_DIR = os.path.join(PATH, \"train\")\n",
    "\n",
    "IMG_WIDTH = 64\n",
    "IMG_HEIGHT = 64\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 16\n",
    "NO_OF_AUGMENTED_IMAGES = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Utv3nryxVrV0"
   },
   "outputs": [],
   "source": [
    "def data_info():\n",
    "    total_number_of_training_images = 0\n",
    "    for root, dirs, files in os.walk(TRAIN_DIR):\n",
    "        for file in files:\n",
    "            total_number_of_training_images += 1\n",
    "\n",
    "    total_number_of_testing_images = 0\n",
    "    for root, dirs, files in os.walk(TEST_DIR):\n",
    "        for file in files:\n",
    "            total_number_of_testing_images += 1\n",
    "\n",
    "    print(\"Total training images:\", total_number_of_training_images)\n",
    "    print(\"Total testing images:\", total_number_of_testing_images, \"\\n\")\n",
    "\n",
    "    return total_number_of_training_images, total_number_of_testing_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(\n",
    "    BEFORE_AUGMENTATION_IMAGES_PATH, AUGMENTED_IMAGES_PATH, NO_OF_AUGMENTED_IMAGES\n",
    "):\n",
    "    image_aug = ImageDataGenerator(\n",
    "        rescale=1.0 / 255,\n",
    "        rotation_range=5,\n",
    "        brightness_range=[0.6, 1.4],\n",
    "        channel_shift_range=50.0,\n",
    "        zoom_range=[0.9, 1.1],\n",
    "    )\n",
    "    no_of_images = 0\n",
    "    for batch in image_aug.flow_from_directory(\n",
    "        batch_size=1,\n",
    "        directory=BEFORE_AUGMENTATION_IMAGES_PATH,\n",
    "        save_to_dir=AUGMENTED_IMAGES_PATH,\n",
    "        save_prefix=\"aug\",\n",
    "        color_mode=\"rgb\",\n",
    "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        class_mode=\"binary\",\n",
    "    ):\n",
    "        no_of_images += 1\n",
    "        if no_of_images >= NO_OF_AUGMENTED_IMAGES:\n",
    "            break\n",
    "\n",
    "\n",
    "# augment_data(BEFORE_AUGMENTATION_IMAGES_PATH, AUGMENTED_IMAGES_PATH, NO_OF_AUGMENTED_IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(path):\n",
    "    destination_path = PATH\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if \"png\" in file:\n",
    "                index = root.rfind(\"\\\\t\")\n",
    "                image = cv2.imread(os.path.join(root, file))\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                clahe = cv2.createCLAHE(clipLimit=0.1, tileGridSize=(8, 8))\n",
    "                image = clahe.apply(image)\n",
    "                print(destination_path + root[index:] + \"\\\\\" + file)\n",
    "                cv2.imwrite(destination_path + root[index:] + \"\\\\\" + file, image)\n",
    "\n",
    "\n",
    "# preprocess_images(AUGMENTED_IMAGES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gnr2xujaVrXe"
   },
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "    image_gen_train = ImageDataGenerator(rescale=1.0 / 255)\n",
    "    train_data_gen = image_gen_train.flow_from_directory(\n",
    "        batch_size=BATCH_SIZE,\n",
    "        directory=TRAIN_DIR,\n",
    "        shuffle=True,\n",
    "        color_mode=\"grayscale\",\n",
    "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        class_mode=\"categorical\",\n",
    "    )\n",
    "\n",
    "    image_gen_val = ImageDataGenerator(rescale=1.0 / 255)\n",
    "    val_data_gen = image_gen_val.flow_from_directory(\n",
    "        batch_size=BATCH_SIZE,\n",
    "        directory=TEST_DIR,\n",
    "        shuffle=True,\n",
    "        color_mode=\"grayscale\",\n",
    "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        class_mode=\"categorical\",\n",
    "    )\n",
    "\n",
    "    return train_data_gen, val_data_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2fjio8EsVrXz"
   },
   "outputs": [],
   "source": [
    "def define_architecture():\n",
    "    model_new = Sequential(\n",
    "        [\n",
    "            Conv2D(\n",
    "                16,\n",
    "                3,\n",
    "                padding=\"same\",\n",
    "                activation=\"relu\",\n",
    "                input_shape=(IMG_HEIGHT, IMG_WIDTH, 1),\n",
    "            ),\n",
    "            MaxPooling2D(),\n",
    "            Dropout(0.5),\n",
    "            Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "            MaxPooling2D(),\n",
    "            Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "            MaxPooling2D(),\n",
    "            Dropout(0.5),\n",
    "            Flatten(),\n",
    "            Dense(512, activation=\"relu\"),\n",
    "            Dense(5, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "    model_new.summary()\n",
    "\n",
    "    return model_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OkIJhS-WVrX1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compile_and_train_cnn(\n",
    "    model_new, train_data_gen, total_train, val_data_gen, total_val\n",
    "):\n",
    "    model_new.compile(\n",
    "        optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    information = model_new.fit_generator(\n",
    "        train_data_gen,\n",
    "        steps_per_epoch=total_train,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=val_data_gen,\n",
    "        validation_steps=total_val,\n",
    "    )\n",
    "\n",
    "    return information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_plot(epochs_range, first_val, second_val, label, plt):\n",
    "    if label == \"Accuracy\":\n",
    "        plt.subplot(1, 2, 1)\n",
    "    else:\n",
    "        plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, first_val, label=\"Training \" + label)\n",
    "    plt.plot(epochs_range, second_val, label=\"Validation \" + label)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7BTeMuNAVrYC"
   },
   "outputs": [],
   "source": [
    "def plot_graphs(information):\n",
    "    acc = information.history[\"accuracy\"]\n",
    "    val_acc = information.history[\"val_accuracy\"]\n",
    "    loss = information.history[\"loss\"]\n",
    "    val_loss = information.history[\"val_loss\"]\n",
    "\n",
    "    epochs_range = range(EPOCHS)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    sub_plot(epochs_range, acc, val_acc, \"Accuracy\", plt)\n",
    "    sub_plot(epochs_range, loss, val_loss, \"Loss\", plt)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_model(model_new):\n",
    "    model_new.save(\"model\")\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(\"model\")\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_quantized_model = converter.convert()\n",
    "    open(\"model.tflite\", \"wb\").write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    total_train, total_val = data_info()\n",
    "    print(total_train, total_val)\n",
    "    train_data_gen, val_data_gen = generate_data()\n",
    "    model_new = define_architecture()\n",
    "    information = compile_and_train_cnn(\n",
    "        model_new, train_data_gen, total_train, val_data_gen, total_val\n",
    "    )\n",
    "    plot_graphs(information)\n",
    "    convert_model(model_new)\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "classification.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
